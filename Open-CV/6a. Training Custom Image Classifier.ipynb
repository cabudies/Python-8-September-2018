{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating/Using Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1 - Create Data for Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HAAR Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cv2.CascadeClassifier('cascade/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to extract the face of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_extractor(image):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    faces = classifier.detectMultiScale(gray_image, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = image[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open video camera to take picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = input('Enter the name of the user for whom you are going to train the model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_directory(name):\n",
    "    file_name_path = 'faces/user/' + name\n",
    "    if (not path.isdir(file_name_path)):\n",
    "        try:\n",
    "            os.mkdir(file_name_path)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "while(True):\n",
    "    ret, frame = video.read()\n",
    "    face = frame\n",
    "    if ((face_extractor(frame) is not None) & (checking_directory(name))):\n",
    "        count = count + 1\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = 'faces/user/' + name + \"/\" + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), \n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "    cv2.imshow('Face Cropper', face)\n",
    "    \n",
    "    # the program will take 5 pictures of the user\n",
    "    if cv2.waitKey(1) == 13 or count == 5: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "if (count<3): \n",
    "    print(\"Unable to get user's face. Kindly run this code again.\")\n",
    "else:\n",
    "    print(\"Face extraction complete. Now, start training the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our classifier for image recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_path = 'faces/user/' + '1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_image = face_recognition.load_image_file(file_name_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_image_encoding = face_recognition.face_encodings(user_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_face_name = ['Gurjas']\n",
    "# user_face_name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trained_faces.dat', 'wb') as f:\n",
    "    pickle.dump(user_image_encoding, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_image = face_recognition.load_image_file('DSC_6160.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_locations = face_recognition.face_locations(unknown_image)\n",
    "face_encodings = face_recognition.face_encodings(unknown_image, face_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image = Image.fromarray(unknown_image)\n",
    "# Create a Pillow ImageDraw Draw instance to draw with\n",
    "draw = ImageDraw.Draw(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each face found in the unknown image\n",
    "for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "    # See if the face is a match for the known face(s)\n",
    "    matches = face_recognition.compare_faces(user_image_encoding, \n",
    "                                             face_encoding)\n",
    "\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    # If a match was found in known_face_encodings, just use the first one.\n",
    "    if True in matches:\n",
    "        first_match_index = matches.index(True)\n",
    "        name = user_face_name[first_match_index]\n",
    "\n",
    "    # Draw a box around the face using the Pillow module\n",
    "    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
    "\n",
    "    # Draw a label with a name below the face\n",
    "    text_width, text_height = draw.textsize(name)\n",
    "    draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n",
    "    draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n",
    "\n",
    "\n",
    "# Remove the drawing library from memory as per the Pillow docs\n",
    "del draw\n",
    "\n",
    "# Display the resulting image\n",
    "pil_image.show()\n",
    "\n",
    "# You can also save a copy of the new image to disk if you want by uncommenting this line\n",
    "pil_image.save(\"identified_images.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
